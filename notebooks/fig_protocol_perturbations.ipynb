{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol Perturbations Figure\n",
    "\n",
    "Generates the protocol instability figure comparing verdict stability across protocols and nuanced verdict fate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# =============================================================================\n# FIGURE: Protocol Instability + Nuanced Verdict Fate (Content vs Protocol)\n# Panel A: Protocol instability by base judgment (separated by protocol)\n# Panel B: Nuanced verdict fate - Content (top) vs Protocol (bottom)\n# =============================================================================\n\n# Load data\nprotocol_df = pd.read_parquet('../data/protocol_tests_combined.parquet')\ncontent_df = pd.read_parquet('../data/master_final_model_own_baseline.parquet')\n\nbaseline_content = content_df[content_df['perturbation_type'] == 'none'][['id', 'model', 'run_number', 'standardized_judgment']].copy()\nbaseline_content = baseline_content.rename(columns={'standardized_judgment': 'baseline_verdict'})\nperturbed_content = content_df[content_df['perturbation_type'] != 'none'].copy()\ncontent_merged = perturbed_content.merge(baseline_content, on=['id', 'model', 'run_number'], how='left')\n\nverdict_labels = {\n    'Other_At_Fault': 'Other At Fault',\n    'Self_At_Fault': 'Self At Fault', \n    'All_At_Fault': 'All At Fault',\n    'No_One_At_Fault': 'No One At Fault',\n    'Unclear': 'Unclear',\n}\nverdict_categories = ['Other_At_Fault', 'Self_At_Fault', 'All_At_Fault', 'No_One_At_Fault']\n\n# Structured protocols + unstructured\nprotocols = ['explanation_first', 'system_prompt', 'unstructured']\nprotocol_display = {'explanation_first': 'Explanation First', 'system_prompt': 'System Prompt', 'unstructured': 'Unstructured'}\n\n# Calculate flip rates for all protocols (for standard verdict categories)\nprotocol_flip_data = []\nfor proto in protocols:\n    proto_df = protocol_df[protocol_df['protocol'] == proto]\n    for base in verdict_categories:\n        subset = proto_df[proto_df['main_study_verdict'] == base]\n        n = len(subset)\n        if n > 0:\n            flipped = (subset['standardized_judgment'] != subset['main_study_verdict']).sum()\n            rate = flipped / n * 100\n            p = flipped / n\n            z = 1.96\n            denom = 1 + z**2/n\n            spread = z * np.sqrt((p*(1-p) + z**2/(4*n))/n) / denom\n            ci = spread * 100\n            protocol_flip_data.append({'protocol': proto, 'verdict': base, 'flip_rate': rate, 'ci': ci})\n\n# Add \"Unclear\" category: rate at which each protocol produces Unclear/No_Verdict outcomes\nfor proto in protocols:\n    proto_df = protocol_df[protocol_df['protocol'] == proto]\n    n = len(proto_df)\n    if n > 0:\n        # Count outcomes that are Unclear, No_Verdict, or similar\n        unclear_count = proto_df['standardized_judgment'].isin(['Unclear', 'No_Verdict', 'unclear', 'no_verdict']).sum()\n        rate = unclear_count / n * 100\n        p = unclear_count / n\n        z = 1.96\n        denom = 1 + z**2/n\n        spread = z * np.sqrt((p*(1-p) + z**2/(4*n))/n) / denom\n        ci = spread * 100\n        protocol_flip_data.append({'protocol': proto, 'verdict': 'Unclear', 'flip_rate': rate, 'ci': ci})\n\nprotocol_flip_df = pd.DataFrame(protocol_flip_data)\n\n# Nuanced fate - Protocol (structured only)\nstructured_protocols = ['explanation_first', 'system_prompt']\nstructured_df = protocol_df[protocol_df['protocol'].isin(structured_protocols)].copy()\nnuanced_protocol = structured_df[structured_df['main_study_verdict'].isin(['All_At_Fault', 'No_One_At_Fault'])]\ntotal_nuanced_proto = len(nuanced_protocol)\n\nproto_pcts = {\n    'Retained': ((nuanced_protocol['standardized_judgment'] == 'All_At_Fault') | \n                 (nuanced_protocol['standardized_judgment'] == 'No_One_At_Fault')).sum() / total_nuanced_proto * 100,\n    'Other At Fault': (nuanced_protocol['standardized_judgment'] == 'Other_At_Fault').sum() / total_nuanced_proto * 100,\n    'Self At Fault': (nuanced_protocol['standardized_judgment'] == 'Self_At_Fault').sum() / total_nuanced_proto * 100,\n}\n\n# Nuanced fate - Content\nnuanced_content = content_merged[content_merged['baseline_verdict'].isin(['All_At_Fault', 'No_One_At_Fault'])]\ntotal_nuanced_content = len(nuanced_content)\n\ncontent_pcts = {\n    'Retained': ((nuanced_content['standardized_judgment'] == 'All_At_Fault') | \n                 (nuanced_content['standardized_judgment'] == 'No_One_At_Fault')).sum() / total_nuanced_content * 100,\n    'Other At Fault': (nuanced_content['standardized_judgment'] == 'Other_At_Fault').sum() / total_nuanced_content * 100,\n    'Self At Fault': (nuanced_content['standardized_judgment'] == 'Self_At_Fault').sum() / total_nuanced_content * 100,\n}\n\n# === CREATE FIGURE ===\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), dpi=150)\n\n# --- Panel A ---\n# Order by average flip rate, but put Unclear at the end\nverdict_categories_with_unclear = verdict_categories + ['Unclear']\navg_flip = protocol_flip_df[protocol_flip_df['verdict'] != 'Unclear'].groupby('verdict')['flip_rate'].mean().sort_values(ascending=False)\nverdict_order = avg_flip.index.tolist() + ['Unclear']\n\nx = np.arange(len(verdict_order))\nwidth = 0.25  # Narrower bars for 3 protocols\ncolors = {'explanation_first': '#444444', 'system_prompt': '#999999', 'unstructured': '#cccccc'}\nhatches = {'explanation_first': '', 'system_prompt': '', 'unstructured': '//'}\n\nfor i, proto in enumerate(protocols):\n    offset = (i - 1) * width  # Center the 3 bars\n    rates = []\n    cis = []\n    for v in verdict_order:\n        match = protocol_flip_df[(protocol_flip_df['verdict'] == v) & (protocol_flip_df['protocol'] == proto)]\n        if len(match) > 0:\n            rates.append(match['flip_rate'].values[0])\n            cis.append(match['ci'].values[0])\n        else:\n            rates.append(0)\n            cis.append(0)\n    rates = np.array(rates)\n    cis = np.array(cis)\n    \n    bars = ax1.bar(x + offset, rates, width, label=protocol_display[proto], \n                   color=colors[proto], edgecolor='#222222', linewidth=0.5,\n                   hatch=hatches[proto])\n    ax1.errorbar(x + offset, rates, yerr=cis, fmt='none', ecolor='#222222', capsize=3, lw=1)\n\n# Add vertical separator before Unclear\nax1.axvline(x=len(verdict_order) - 1.5, color='#888888', linestyle='--', linewidth=1, alpha=0.5)\n\nax1.set_xlabel('Main Study Verdict', fontweight='bold')\nax1.set_ylabel('Flip Rate (%) / Unclear Rate (%)', fontweight='bold')\nax1.set_title('(A) Protocol Instability by Base Judgment', fontweight='bold', loc='left')\nax1.set_xticks(x)\nax1.set_xticklabels([verdict_labels.get(v, v) for v in verdict_order], rotation=15, ha='right')\nax1.set_ylim(0, 100)  # Increased to accommodate unstructured's higher rates\nax1.legend(loc='upper right', framealpha=0.9)\nax1.grid(axis='y', alpha=0.3, linestyle='--')\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# --- Panel B: Legend for segment colors, only percentages in bars ---\nbar_height = 0.25\ny_positions = [0.55, 0.15]\nrow_labels = ['Content Perturbations', 'Protocol Perturbations']\nrow_data = [content_pcts, proto_pcts]\n\nseg_colors = {'Retained': '#bbbbbb', 'Other At Fault': '#333333', 'Self At Fault': '#666666'}\nsegment_order = ['Retained', 'Other At Fault', 'Self At Fault']\n\nfor y_pos, row_label, data in zip(y_positions, row_labels, row_data):\n    left = 0\n    for seg in segment_order:\n        val = data[seg]\n        ax2.barh(y_pos, val, left=left, color=seg_colors[seg], edgecolor='#222222', \n                 linewidth=0.5, height=bar_height)\n        \n        # Only percentages inside bars\n        if val > 4:\n            text_color = 'white' if seg in ['Other At Fault', 'Self At Fault'] else 'black'\n            ax2.text(left + val/2, y_pos, f'{val:.0f}%', ha='center', va='center', \n                    fontsize=9, fontweight='bold', color=text_color)\n        \n        left += val\n    \n    # Row label below the bar\n    ax2.text(50, y_pos - 0.17, row_label, ha='center', va='top', fontsize=9, fontstyle='italic')\n\n# Create legend\nlegend_handles = [mpatches.Patch(facecolor=seg_colors[seg], edgecolor='#222222', label=seg) \n                  for seg in segment_order]\nax2.legend(handles=legend_handles, loc='upper right', framealpha=0.9, fontsize=8)\n\nax2.set_xlim(0, 100)\nax2.set_ylim(-0.15, 0.85)\nax2.set_xlabel('Percentage', fontweight='bold')\nax2.set_title('(B) Nuanced Verdict Fate (All At Fault + No One At Fault)', fontweight='bold', loc='left')\nax2.set_yticks([])\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\nax2.spines['left'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('../figures/fig_protocol_instability_with_fate.pdf', bbox_inches='tight', dpi=300)\nplt.savefig('../figures/fig_protocol_instability_with_fate.png', bbox_inches='tight', dpi=300)\nplt.show()\n\nprint(\"Saved: fig_protocol_instability_with_fate.pdf/png\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}