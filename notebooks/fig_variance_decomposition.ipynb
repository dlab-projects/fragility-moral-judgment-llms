{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Variance Decomposition Analysis\n",
    "\n",
    "This notebook computes the variance decomposition statistics reported in the paper:\n",
    "- Eta-squared (η²) for scenario, perturbation type, and model effects\n",
    "- Correlation between baseline inter-model disagreement and flip rates\n",
    "- Flip rates by baseline disagreement level\n",
    "- Text property correlations\n",
    "\n",
    "**Key finding**: Instability is primarily a property of individual scenarios (16.4% of variance) rather than perturbation types (3.3%) or models (<0.1%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Publication settings\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 11,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 9,\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "})\n",
    "\n",
    "FIGURE_DIR = Path('../figures')\n",
    "FIGURE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load master data\n",
    "df = pd.read_parquet('../data/content_eval.parquet')\n",
    "print(f'Total records: {len(df):,}')\n",
    "print(f'Models: {df[\"model\"].unique().tolist()}')\n",
    "print(f'Perturbation types: {df[\"perturbation_type\"].nunique()}')\n",
    "print(f'Scenarios: {df[\"id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-perturbations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to perturbation data only (exclude baseline)\n",
    "pert_df = df[df['perturbation_type'] != 'none'].copy()\n",
    "pert_df['flipped_int'] = pert_df['verdict_flipped'].astype(int)\n",
    "\n",
    "print(f'Perturbation records: {len(pert_df):,}')\n",
    "print(f'Grand mean flip rate: {pert_df[\"flipped_int\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variance-decomp-header",
   "metadata": {},
   "source": [
    "## 1. Simple Eta-Squared Decomposition\n",
    "\n",
    "We compute eta-squared (η²) as SS_factor / SS_total for each factor independently.\n",
    "\n",
    "$$\\eta^2 = \\frac{SS_{\\text{factor}}}{SS_{\\text{total}}}$$\n",
    "\n",
    "where:\n",
    "- $SS_{\\text{total}} = \\sum_i (y_i - \\bar{y})^2$\n",
    "- $SS_{\\text{factor}} = \\sum_j n_j (\\bar{y}_j - \\bar{y})^2$\n",
    "\n",
    "**Note**: This is a simple effect-size decomposition. Factor contributions can overlap (they don't sum to 100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variance-decomp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eta_squared(data, outcome_col, factor_col):\n",
    "    \"\"\"Compute eta-squared for a single factor.\"\"\"\n",
    "    grand_mean = data[outcome_col].mean()\n",
    "    SS_total = ((data[outcome_col] - grand_mean) ** 2).sum()\n",
    "    \n",
    "    factor_means = data.groupby(factor_col)[outcome_col].mean()\n",
    "    n_per_level = data.groupby(factor_col).size()\n",
    "    SS_factor = (n_per_level * (factor_means - grand_mean) ** 2).sum()\n",
    "    \n",
    "    eta2 = SS_factor / SS_total\n",
    "    return eta2, SS_factor, SS_total\n",
    "\n",
    "# Compute for each factor\n",
    "print('='*70)\n",
    "print('SIMPLE ETA-SQUARED DECOMPOSITION')\n",
    "print('='*70)\n",
    "print(f'\\nN = {len(pert_df):,} observations')\n",
    "print(f'Grand mean flip rate: {pert_df[\"flipped_int\"].mean():.4f}\\n')\n",
    "\n",
    "results = {}\n",
    "for factor, label in [('id', 'Scenario'), ('perturbation_type', 'Perturbation'), ('model', 'Model')]:\n",
    "    eta2, ss_factor, ss_total = compute_eta_squared(pert_df, 'flipped_int', factor)\n",
    "    n_levels = pert_df[factor].nunique()\n",
    "    results[label] = {'eta2': eta2, 'n_levels': n_levels, 'ss': ss_factor}\n",
    "    print(f'{label:<15}: η² = {eta2:.4f} ({eta2*100:.1f}%)  [k={n_levels} levels]')\n",
    "\n",
    "print(f'\\nSS_total: {ss_total:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anova-header",
   "metadata": {},
   "source": [
    "## 2. Type II ANOVA (Validation)\n",
    "\n",
    "For validation, we also run a proper Type II ANOVA on a stratified subsample. This partitions variance accounting for other factors in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anova",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Sample scenarios for computational tractability\n",
    "np.random.seed(42)\n",
    "scenario_sample = pert_df['id'].drop_duplicates().sample(n=500)\n",
    "anova_data = pert_df[pert_df['id'].isin(scenario_sample)].copy()\n",
    "\n",
    "print(f'ANOVA subsample: {len(anova_data):,} observations from {len(scenario_sample)} scenarios')\n",
    "\n",
    "# Fit model (main effects only)\n",
    "model = ols('flipped_int ~ C(id) + C(perturbation_type) + C(model)', data=anova_data).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "print('\\nType II ANOVA Results:')\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# Compute eta-squared from ANOVA\n",
    "SS_total_anova = anova_table['sum_sq'].sum()\n",
    "print('\\nEta-squared from ANOVA:')\n",
    "for effect in ['C(id)', 'C(perturbation_type)', 'C(model)']:\n",
    "    if effect in anova_table.index:\n",
    "        eta2 = anova_table.loc[effect, 'sum_sq'] / SS_total_anova\n",
    "        print(f'  {effect:<25}: η² = {eta2:.4f} ({eta2*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## 3. Comparison: Simple vs ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('COMPARISON: Simple η² vs Type II ANOVA η²')\n",
    "print('='*70)\n",
    "print(f'\\n{\"Factor\":<15} {\"Simple η²\":>12} {\"ANOVA η²\":>12}')\n",
    "print('-'*40)\n",
    "\n",
    "anova_eta = {\n",
    "    'Scenario': anova_table.loc['C(id)', 'sum_sq'] / SS_total_anova,\n",
    "    'Perturbation': anova_table.loc['C(perturbation_type)', 'sum_sq'] / SS_total_anova,\n",
    "    'Model': anova_table.loc['C(model)', 'sum_sq'] / SS_total_anova,\n",
    "}\n",
    "\n",
    "for label in ['Scenario', 'Perturbation', 'Model']:\n",
    "    simple = results[label]['eta2']\n",
    "    anova = anova_eta[label]\n",
    "    print(f'{label:<15} {simple*100:>11.1f}% {anova*100:>11.1f}%')\n",
    "\n",
    "print('\\n** Conclusion: Both methods yield comparable estimates **')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disagreement-header",
   "metadata": {},
   "source": [
    "## 4. Baseline Disagreement Predicts Flip Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disagreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline data (run 1 only for inter-model comparison)\n",
    "baseline = df[(df['perturbation_type'] == 'none') & (df['run_number'] == 1)].copy()\n",
    "\n",
    "# Compute baseline disagreement per scenario (number of unique verdicts across 4 models)\n",
    "baseline_disagreement = baseline.groupby('id')['standardized_judgment'].apply(\n",
    "    lambda x: len(x.unique())\n",
    ").rename('n_unique_verdicts')\n",
    "\n",
    "# Compute scenario flip rates\n",
    "scenario_flip_rate = pert_df.groupby('id')['verdict_flipped'].mean()\n",
    "\n",
    "# Merge\n",
    "scenario_stats = pd.DataFrame({\n",
    "    'n_unique_verdicts': baseline_disagreement,\n",
    "    'flip_rate': scenario_flip_rate\n",
    "}).dropna()\n",
    "\n",
    "print(f'Scenarios with both metrics: {len(scenario_stats):,}')\n",
    "\n",
    "# Correlation\n",
    "r, p = stats.pearsonr(scenario_stats['n_unique_verdicts'], scenario_stats['flip_rate'])\n",
    "print(f'\\nCorrelation (baseline disagreement vs flip rate):')\n",
    "print(f'  r = {r:.2f}, p = {p:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disagreement-by-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip rates by disagreement level\n",
    "print('\\nFlip rates by baseline disagreement:')\n",
    "print('-' * 55)\n",
    "print(f'{\"# Unique Verdicts\":<20} {\"Mean Flip Rate\":>15} {\"N\":>10}')\n",
    "print('-' * 55)\n",
    "\n",
    "for n_verdicts in [1, 2, 3, 4]:\n",
    "    mask = scenario_stats['n_unique_verdicts'] == n_verdicts\n",
    "    if mask.sum() > 0:\n",
    "        mean_flip = scenario_stats.loc[mask, 'flip_rate'].mean() * 100\n",
    "        count = mask.sum()\n",
    "        label = 'Unanimous' if n_verdicts == 1 else f'{n_verdicts} different'\n",
    "        print(f'{label:<20} {mean_flip:>14.1f}% {count:>10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "text-props-header",
   "metadata": {},
   "source": [
    "## 5. Text Property Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text-props",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline data for text features\n",
    "baseline_features = baseline.groupby('id').first().reset_index()\n",
    "\n",
    "# Compute text features\n",
    "baseline_features['text_length'] = baseline_features['perturbed_text'].str.len()\n",
    "baseline_features['word_count'] = baseline_features['perturbed_text'].str.split().str.len()\n",
    "baseline_features['question_marks'] = baseline_features['perturbed_text'].str.count(r'\\?')\n",
    "baseline_features['exclamation_marks'] = baseline_features['perturbed_text'].str.count(r'!')\n",
    "baseline_features['period_count'] = baseline_features['perturbed_text'].str.count(r'\\.')\n",
    "\n",
    "# Merge with flip rates\n",
    "baseline_features = baseline_features.merge(\n",
    "    scenario_flip_rate.rename('flip_rate'),\n",
    "    left_on='id', right_index=True,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print('Text Property Correlations with Flip Rate:')\n",
    "print('-' * 50)\n",
    "print(f'{\"Feature\":<25} {\"r\":>10} {\"p-value\":>12}')\n",
    "print('-' * 50)\n",
    "\n",
    "text_features = ['text_length', 'word_count', 'question_marks', 'exclamation_marks', 'period_count']\n",
    "for feat in text_features:\n",
    "    r, p = stats.pearsonr(baseline_features[feat], baseline_features['flip_rate'])\n",
    "    print(f'{feat:<25} {r:>+10.3f} {p:>12.4f}')\n",
    "\n",
    "print('\\n** All correlations |r| < 0.05, confirming flips reflect moral ambiguity **')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), dpi=150)\n",
    "\n",
    "# Panel A: Eta-squared by factor\n",
    "ax = axes[0]\n",
    "factors = ['Scenario', 'Perturbation', 'Model']\n",
    "eta_values = [results[f]['eta2'] * 100 for f in factors]\n",
    "colors = ['#222222', '#666666', '#aaaaaa']\n",
    "\n",
    "bars = ax.bar(factors, eta_values, color=colors, edgecolor='#222222', linewidth=0.5)\n",
    "\n",
    "for bar, val in zip(bars, eta_values):\n",
    "    ax.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords='offset points', ha='center', va='bottom',\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Variance Explained (η²)', fontweight='bold')\n",
    "ax.set_title('(A) Variance Decomposition', fontweight='bold', loc='left')\n",
    "ax.set_ylim(0, 20)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Panel B: Flip rate by baseline disagreement\n",
    "ax = axes[1]\n",
    "disagreement_levels = [1, 2, 3, 4]\n",
    "flip_rates = [scenario_stats[scenario_stats['n_unique_verdicts'] == n]['flip_rate'].mean() * 100 \n",
    "              for n in disagreement_levels]\n",
    "counts = [scenario_stats[scenario_stats['n_unique_verdicts'] == n].shape[0] \n",
    "          for n in disagreement_levels]\n",
    "\n",
    "bars = ax.bar(disagreement_levels, flip_rates, color='#444444', edgecolor='#222222', linewidth=0.5)\n",
    "\n",
    "for bar, val, n in zip(bars, flip_rates, counts):\n",
    "    ax.annotate(f'{val:.1f}%\\n(n={n})', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords='offset points', ha='center', va='bottom',\n",
    "                fontsize=9)\n",
    "\n",
    "ax.set_xlabel('# Unique Baseline Verdicts (across 4 models)', fontweight='bold')\n",
    "ax.set_ylabel('Mean Flip Rate (%)', fontweight='bold')\n",
    "ax.set_title('(B) Baseline Disagreement Predicts Instability', fontweight='bold', loc='left')\n",
    "ax.set_xticks(disagreement_levels)\n",
    "ax.set_xticklabels(['1\\n(Unanimous)', '2', '3', '4\\n(All different)'])\n",
    "ax.set_ylim(0, 45)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add correlation annotation\n",
    "ax.annotate(f'r = {r:.2f}***', xy=(0.95, 0.95), xycoords='axes fraction',\n",
    "            ha='right', va='top', fontsize=10, fontstyle='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURE_DIR / 'variance_decomposition.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(FIGURE_DIR / 'variance_decomposition.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "print('Saved: variance_decomposition.pdf/png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('SUMMARY STATISTICS FOR PAPER')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n--- Variance Decomposition (Simple η²) ---')\n",
    "print(f'  Scenario:     η² = {results[\"Scenario\"][\"eta2\"]:.4f} ({results[\"Scenario\"][\"eta2\"]*100:.1f}%)')\n",
    "print(f'  Perturbation: η² = {results[\"Perturbation\"][\"eta2\"]:.4f} ({results[\"Perturbation\"][\"eta2\"]*100:.1f}%)')\n",
    "print(f'  Model:        η² = {results[\"Model\"][\"eta2\"]:.6f} ({results[\"Model\"][\"eta2\"]*100:.3f}%)')\n",
    "\n",
    "print('\\n--- Baseline Disagreement vs Flip Rate ---')\n",
    "r, p = stats.pearsonr(scenario_stats['n_unique_verdicts'], scenario_stats['flip_rate'])\n",
    "print(f'  Correlation: r = {r:.2f}, p < 0.001')\n",
    "\n",
    "unanimous = scenario_stats[scenario_stats['n_unique_verdicts'] == 1]['flip_rate'].mean() * 100\n",
    "four_diff = scenario_stats[scenario_stats['n_unique_verdicts'] == 4]['flip_rate'].mean() * 100\n",
    "print(f'  Unanimous baseline (1 verdict): {unanimous:.1f}% flip rate')\n",
    "print(f'  4 different verdicts: {four_diff:.1f}% flip rate')\n",
    "\n",
    "print('\\n--- Text Property Correlations ---')\n",
    "print('  All |r| < 0.05')\n",
    "\n",
    "print('\\n--- Suggested Paper Text ---')\n",
    "print(f'''\n",
    "\"Variance decomposition reveals that instability is primarily a property of \n",
    "individual scenarios rather than perturbation types or models. We computed \n",
    "eta-squared (η²) as SS_factor / SS_total for each factor independently. \n",
    "Scenario-level differences account for {results[\"Scenario\"][\"eta2\"]*100:.1f}% of variance \n",
    "(η² = {results[\"Scenario\"][\"eta2\"]:.3f}), while perturbation type explains only {results[\"Perturbation\"][\"eta2\"]*100:.1f}% \n",
    "and model differences are negligible (η² < 0.001). [...] baseline inter-model \n",
    "disagreement strongly predicts flip rates (r = {r:.2f}, p < 0.001): scenarios \n",
    "with unanimous baseline agreement show only {unanimous:.1f}% flips versus {four_diff:.1f}% \n",
    "for scenarios with four different baseline verdicts.\"\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
